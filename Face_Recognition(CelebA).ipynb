{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgPNO518-00P"
   },
   "source": [
    "# **Face Recognition (CelebA dataset)**\n",
    "\n",
    "\n",
    "> Performed Facial Recognition using CNN as well as VGG16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REwOZHk0PX-5"
   },
   "source": [
    "### **Using CNN:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Crygw9tJPaz9"
   },
   "source": [
    "\n",
    "> Code Summary:\n",
    "\n",
    "*   the code loads facial attribute data, prepares image and label data, builds a CNN model, trains it using the generated data, and evaluates its performance.\n",
    "\n",
    "*   The model aims to classify whether a person is smiling or not based on the provided facial images.\n",
    "\n",
    "*   The accuracy score and classification report provide insights into the model's performance in predicting the smiling attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "sBKObZGoPTiA"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gosd88t0aKqi"
   },
   "source": [
    "Here due to memory issue in my local system I have used a subset of the actual dataset with 100 records - which may affect accuracy;\n",
    "\n",
    "> Described about it in detail in challenges and limitations at the end\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "vNnk7iQmPTr9"
   },
   "outputs": [],
   "source": [
    "# Path to the CelebA dataset\n",
    "dataset_dir = '/content/sample_data/celeba/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "WXGeNTTqcBku"
   },
   "outputs": [],
   "source": [
    "# Load the CelebA dataset annotations\n",
    "annotations_df = pd.read_csv('/content/sample_data/list_attr_celeba.csv')\n",
    "annotations_df = annotations_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gR5O4lqpPTzK",
    "outputId": "a59e9050-6d22-4e63-b2d3-75bf7c83158a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
       "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
       "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
       "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
       "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
       "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
       "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
       "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
       "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
       "       'Wearing_Necktie', 'Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "KVvCY_v_PT2a"
   },
   "outputs": [],
   "source": [
    "# Select relevant columns for facial recognition\n",
    "selected_attributes = ['image_id', 'Smiling', 'Male', 'Young']\n",
    "data = annotations_df[selected_attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "SCXyJZIcPT5q"
   },
   "outputs": [],
   "source": [
    "# Remove images with missing attributes\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "jgtOELmjQX9t"
   },
   "outputs": [],
   "source": [
    "# Define the target attribute\n",
    "target_attribute = 'Smiling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "JmiaM3U3QYCp"
   },
   "outputs": [],
   "source": [
    "# Prepare the image data\n",
    "image_dir = os.path.join(dataset_dir)\n",
    "image_files = data['image_id'].values\n",
    "images = []\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "    images.append(image)\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "MTwkc4dMQYHR"
   },
   "outputs": [],
   "source": [
    "# Prepare the target labels\n",
    "labels = data[target_attribute].values\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "MxKeTgAAQYLn"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "r-_xkITZQpoh"
   },
   "outputs": [],
   "source": [
    "# Preprocess the image data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "tdvr_GBcQxBz"
   },
   "outputs": [],
   "source": [
    "# Build the facial recognition model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(218, 178, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpWux_v8QxNZ",
    "outputId": "fa7df1ae-2d0e-4e4b-d9ff-2f5a09a536a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 5s 1s/step - loss: 2.9669 - accuracy: 0.4750 - val_loss: 1.0651 - val_accuracy: 0.5500\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 7s 3s/step - loss: 2.0267 - accuracy: 0.5125 - val_loss: 0.9802 - val_accuracy: 0.4500\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7549 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.7372 - accuracy: 0.4750 - val_loss: 0.7048 - val_accuracy: 0.4500\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6333 - accuracy: 0.6750 - val_loss: 0.7055 - val_accuracy: 0.4500\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.5302 - accuracy: 0.7500 - val_loss: 0.7501 - val_accuracy: 0.4500\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.4960 - accuracy: 0.8125 - val_loss: 0.8175 - val_accuracy: 0.4500\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3634 - accuracy: 0.8875 - val_loss: 0.6168 - val_accuracy: 0.7000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.2894 - accuracy: 0.9000 - val_loss: 0.5967 - val_accuracy: 0.6500\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.3056 - accuracy: 0.8625 - val_loss: 0.8510 - val_accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbfc3b2d1e0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tt6zmpRHQ3Vm",
    "outputId": "be8a8358-7152-4e30-97ee-ce5b066ae0de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 276ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_predictions = model.predict(test_generator)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "test_labels = np.argmax(y_test, axis=1)\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "classification_report = classification_report(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CP9NIXg8RfME",
    "outputId": "24a0ac7e-53cb-4f2c-e5e8-57d69ff7e646"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  45.0 %\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with actual and predicted values\n",
    "df = pd.DataFrame({'Actual': le.inverse_transform(test_labels), 'Predicted': le.inverse_transform(test_predictions)})\n",
    "\n",
    "# Accuracy:\n",
    "print(\"Accuracy: \", accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywqtnuYnQYag",
    "outputId": "7515c7f7-a18f-427d-add2-5ef8d2f5dc34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.89      0.59         9\n",
      "           1       0.50      0.09      0.15        11\n",
      "\n",
      "    accuracy                           0.45        20\n",
      "   macro avg       0.47      0.49      0.37        20\n",
      "weighted avg       0.47      0.45      0.35        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jarDORpSTB1"
   },
   "source": [
    "Accuracy and Classification Report:\n",
    "\n",
    "\n",
    "> The accuracy for this model is 45.00 %\n",
    "\n",
    "\n",
    "*   The model has higher precision and recall for class 0 (non-smiling)\n",
    "compared to class 1 (smiling).\n",
    "*   The F1-scores indicate that the model's performance is relatively better for class 0.\n",
    "*   The low recall for class 1 suggests that the model struggles to identify actual instances of smiling correctly.\n",
    "*   The accuracy of the model is 45%, indicating that it is not performing well in accurately classifying smiling and non-smiling attributes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oeu_3_4TfYaR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uWNDlVVPE_4"
   },
   "source": [
    "**Using VGG16**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzNto_mxPFZy"
   },
   "source": [
    "> Code Summary:\n",
    "\n",
    "\n",
    "*   The methodology involves training a deep learning model with pre-trained **VGG16** as the base model.\n",
    "\n",
    "*  The model is trained using image data generators and the binary\n",
    "cross-entropy loss function.\n",
    "\n",
    "*   The results obtained include accuracy scores and confusion matrices showing for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "howv3Ass0VS6"
   },
   "outputs": [],
   "source": [
    "# Required Libraries:\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9Cco8yCl0VWa"
   },
   "outputs": [],
   "source": [
    "# Set the path to the CelebA dataset\n",
    "dataset_dir = '/content/sample_data/celeba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nF8fapDY0Vbv"
   },
   "outputs": [],
   "source": [
    "# Load the CelebA annotations file\n",
    "df_attributes = pd.read_csv('/content/sample_data/list_attr_celeba.csv',low_memory = False)\n",
    "df_attributes = df_attributes.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDr8MJLp6zNE",
    "outputId": "bdc54f9e-6362-4e3c-fd30-3734648f7a8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 41)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7QASlv802oq",
    "outputId": "fe3d8f1c-b2a1-4c72-a949-c70c48dde043"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
       "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
       "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
       "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
       "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
       "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
       "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
       "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
       "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
       "       'Wearing_Necktie', 'Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attributes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Nte9nuoj7US-"
   },
   "outputs": [],
   "source": [
    "# Select relevant columns for facial recognition\n",
    "selected_columns = ['image_id', 'Eyeglasses', 'Smiling', 'Male', 'Young']\n",
    "df = df_attributes[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QsWu34-B7UWK"
   },
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWrgs0tU7UZL",
    "outputId": "eeef1124-056c-4099-b374-fc38ee6000c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 validated image filenames.\n",
      "Found 20 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators for training and testing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=dataset_dir,\n",
    "    x_col='image_id',\n",
    "    y_col=selected_columns[1:],\n",
    "    class_mode='raw',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=dataset_dir,\n",
    "    x_col='image_id',\n",
    "    y_col=selected_columns[1:],\n",
    "    class_mode='raw',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9qfZeBvJ7Ugv"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "fWBUaUpk7UkZ"
   },
   "outputs": [],
   "source": [
    "# Create the facial recognition model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(selected_columns[1:]), activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zABy-uYt7UmD",
    "outputId": "9f353f6c-9185-4bec-c96e-2edc12963cef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbGHfQoq7Up_",
    "outputId": "07c8222a-32bc-4f43-d2da-ea26db9a2e39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 123s 37s/step - loss: -6695.9663 - accuracy: 0.3125 - val_loss: -1930682.2500 - val_accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 110s 34s/step - loss: -90571064.0000 - accuracy: 0.2750 - val_loss: -3309145600.0000 - val_accuracy: 0.3000\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 112s 36s/step - loss: -45771870208.0000 - accuracy: 0.2750 - val_loss: -552331837440.0000 - val_accuracy: 0.3000\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 109s 44s/step - loss: -3723271864320.0000 - accuracy: 0.2750 - val_loss: -30442130505728.0000 - val_accuracy: 0.3000\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 109s 34s/step - loss: -90501378211840.0000 - accuracy: 0.2750 - val_loss: -858967420960768.0000 - val_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 112s 46s/step - loss: -3145520230957056.0000 - accuracy: 0.2750 - val_loss: -14832664188026880.0000 - val_accuracy: 0.3000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 116s 48s/step - loss: -43203118980136960.0000 - accuracy: 0.2750 - val_loss: -197590039171956736.0000 - val_accuracy: 0.3000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 109s 44s/step - loss: -497918169965395968.0000 - accuracy: 0.2750 - val_loss: -1990161813446066176.0000 - val_accuracy: 0.3000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 112s 36s/step - loss: -4157784803615178752.0000 - accuracy: 0.2750 - val_loss: -16592293468651388928.0000 - val_accuracy: 0.3000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 109s 34s/step - loss: -33391488637371154432.0000 - accuracy: 0.2750 - val_loss: -115167149182746099712.0000 - val_accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=10, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeNqbr9s7qqZ",
    "outputId": "3341934d-04f9-4f1e-915e-15321d019e6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_generator.reset()\n",
    "pred_prob = model.predict(test_generator)\n",
    "pred_labels = (pred_prob > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ANIpBJq77sN2"
   },
   "outputs": [],
   "source": [
    "# Convert predictions and actual values to a DataFrame\n",
    "columns = selected_columns[1:]\n",
    "actual_values = pd.DataFrame(test_generator.labels, columns=columns)\n",
    "predicted_values = pd.DataFrame(pred_labels, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVALJ9qb7ugT",
    "outputId": "dbe206f0-b331-4fbc-bee0-c8b4cdde0ee7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate accuracy for each attribute\n",
    "accuracy = pd.DataFrame([accuracy_score(actual_values[attr], predicted_values[attr]) for attr in columns])\n",
    "\n",
    "# Combine actual and predicted values with accuracy\n",
    "results = pd.concat([actual_values, predicted_values, accuracy], axis=1, keys=['Actual', 'Predicted', 'Accuracy'])\n",
    "accuracy.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XerYnfoW_hxe",
    "outputId": "a3c90baf-de44-4249-806c-ab9b3bc4b568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrice:\n",
      "\n",
      "Attribute: Eyeglasses\n",
      "[[ 0 20]\n",
      " [ 0  0]]\n",
      "\n",
      "Attribute: Smiling\n",
      "[[ 0  9  0]\n",
      " [ 0  0  0]\n",
      " [ 0 11  0]]\n",
      "\n",
      "Attribute: Male\n",
      "[[ 0 15  0]\n",
      " [ 0  0  0]\n",
      " [ 0  5  0]]\n",
      "\n",
      "Attribute: Young\n",
      "[[ 0  2]\n",
      " [ 0 18]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix for each attribute\n",
    "confusion_matrices = {}\n",
    "for attr in columns:\n",
    "    cm = confusion_matrix(actual_values[attr], predicted_values[attr])\n",
    "    confusion_matrices[attr] = cm\n",
    "print('Confusion Matrice:')\n",
    "for attr in columns:\n",
    "    print(f'\\nAttribute: {attr}')\n",
    "    print(confusion_matrices[attr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A21xDI-uMpGv"
   },
   "source": [
    "### Accuracy and Confusion Matrices:\n",
    "\n",
    "\n",
    "\n",
    ">  The accuracy of this model is 22.50 %\n",
    "\n",
    "\n",
    "> These confusion matrices provide insights into the model's performance for each attribute and highlight the misclassifications made by the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   For \"Eyeglasses,\" all samples are predicted as the negative class (no eyeglasses), resulting in a false negative count of 20.\n",
    "\n",
    "*   For \"Smiling,\" there are no positive predictions for any class, resulting in all zeros.\n",
    "\n",
    "*   For \"Male,\" all samples are predicted as the negative class (not male), resulting in a false negative count of 15.\n",
    "\n",
    "*   For \"Young,\" all samples are predicted as the positive class (young), except for 2 false negatives.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRGxDB_f-zMe"
   },
   "source": [
    "### **Limitations and Challenges:**\n",
    "\n",
    "\n",
    "Due to memory issue in my local system I have used a subset of the actual dataset with 100 records;\n",
    "*  Due to it the model accuracy may get affected as the training data is too small or not diverse enough,\n",
    "*  there may be imbalence of classes where certain attributes may have significantly more samples than others so the model may be biased towards the majority class and struggle to accurately predict the minority class.\n",
    "\n",
    "\n",
    "> To improve accuracy\n",
    "\n",
    "\n",
    "*   the actual dataset  or a larger subset can be used to increase the model training set\n",
    "*   Furthermore, oversampling or undersampling can be employed to balance the classes so that model learns equally from all attribute categories.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MB1pYlFREI7"
   },
   "source": [
    "*From Above we can infer that CNN has higher accuracy than VGG16*\n",
    "\n",
    "*  As here I've took subset of actual dataset - CNN performed well than VGG16; whereas CNN is prone to overfitting on large datasets.\n",
    "*  Also CelebA dataset contains images with variations in lighting, occlusion, and face angles that are better captured by the CNN architecture used, it can result in higher accuracy compared to VGG16.\n",
    "\n",
    "Both models may perform differently based on the input dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLTLvTM5RDAX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
